{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from itertools import compress\n",
    "from itertools import chain\n",
    "from urllib.parse import urljoin\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "data_path = os.path.join(\"D:/\", \"data\", \"drmkc\")\n",
    "pdf_path = os.path.join(data_path, \"pdfs\")\n",
    "\n",
    "filename = \"drr-scrape_total_20210505.json\"\n",
    "\n",
    "with open(os.path.join(data_path, filename), 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "domain_url = \"https://\" + urlparse(data[0].get('url')).netloc\n",
    "pdfs = list(set([urljoin(domain_url, url) for url in list(chain(*[list(compress(entry['links'], [(\".pdf\" in link) for link in entry['links']])) for entry in data]))]))\n",
    "\n",
    "if not os.path.isdir(pdf_path):\n",
    "    os.mkdir(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_kw = ['social media', 'government', 'participatory', 'youtube', 'nongovernmental organizations', 'notifications']\n",
    "\n",
    "data_exclude = [entry for entry in data if not all([kw in exclude_kw for kw in entry.get('keywords_matched')])]\n",
    "\n",
    "#data_exclude[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_links_manual = ['twitter', 'facebook', 'youtube', 'google', 'nature.com', 'zoom.us', 'goo.gl', 'bit.ly', 'flcikr', 't.co', 'medium.com', 'github', 'tandfonline', 'linkedin', 'bbc.co.uk', 'news24.com', 'vimeo', 'dx.doi.org']\n",
    "\n",
    "data_exclude = [entry for entry in data if not any([url in entry.get('url') for url in drop_links_manual])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in data_exclude:\n",
    "    entry['domain_url'] = urlparse(entry.get('url')).netloc\n",
    "\n",
    "domain_urls = list(set([entry.get('domain_url') for entry in data_exclude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pdfs for www.who.int\n",
      "\n",
      "|==                                                | 5.45 %\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d0c898521e79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdf_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl_to_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-d0c898521e79>\u001b[0m in \u001b[0;36murl_to_filename\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0murl_to_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'(https\\:\\/\\/(www\\.)?)|(http\\:\\/\\/(www\\.)?)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0murlpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'(\\w+?)\\.\\w{2,4}(?=\\/)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnamepart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\.\\w{2,4}(\\/.+\\.pdf)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnamepart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnamepart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"?\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "def url_to_filename(url):\n",
    "    url = re.sub(r'(https\\:\\/\\/(www\\.)?)|(http\\:\\/\\/(www\\.)?)', '', url)\n",
    "    urlpart = re.search(r'(\\w+?)\\.\\w{2,4}(?=\\/)', url).group(1)\n",
    "    namepart = re.search(r'\\.\\w{2,4}(\\/.+\\.pdf)', url).group(1).replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n",
    "    namepart = namepart.replace(\"?\", \"\")\n",
    "    filename = urlpart + namepart\n",
    "    return(filename)\n",
    "\n",
    "for domain_url in domain_urls:\n",
    "    \n",
    "    missed_pdfs = []\n",
    "    \n",
    "    save_path = os.path.join(pdf_path, domain_url)\n",
    "    \n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    \n",
    "    domain_set = [entry for entry in data_exclude if entry.get('domain_url') == domain_url]\n",
    "    \n",
    "    url_prefix = \"https://\" + domain_url\n",
    "    \n",
    "    pdfs = list(set([urljoin(url_prefix, url) for url in list(chain(*[list(compress(entry['links'], [(\".pdf\" in link) for link in entry['links']])) for entry in domain_set]))]))\n",
    "    \n",
    "    print(\"downloading pdfs for {}\\n\".format(domain_url))\n",
    "    for c, pdf_url in enumerate(pdfs, start = 1):\n",
    "    \n",
    "        filename = url_to_filename(pdf_url)\n",
    "\n",
    "        if not os.path.isfile(os.path.join(save_path, filename)):\n",
    "            try:\n",
    "                r = requests.get(pdf_url, stream=True)\n",
    "            except:\n",
    "                missed_pdfs.append(pdf_url)\n",
    "                continue\n",
    "                \n",
    "            if r.status_code == 200:\n",
    "                with open(os.path.join(save_path, filename), 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                time.sleep(random.uniform(0.5, 1))\n",
    "            else:\n",
    "                missed_pdfs.append(pdf_url)\n",
    "                continue\n",
    "\n",
    "        progress = \"|{0}| {1:.2f} %\".format((\"=\"*int(c/len(pdfs) * 50)).ljust(50), c/len(pdfs) * 100)\n",
    "    \n",
    "        print(progress, end = \"\\r\")\n",
    "        \n",
    "        with open(os.path.join(save_path, 'missed_pdf.txt'), 'w', encoding = 'utf-8') as f:\n",
    "            for url in missed_pdfs:\n",
    "                f.write(url + \"\\n\")\n",
    "            f.close()\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://info.worldbank.org/governance/wgi/Home/downLoadFile?fileName=va.pdf'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = re.sub(r'(https\\:\\/\\/(www\\.)?)|(http\\:\\/\\/(www\\.)?)', '', pdf_url)\n",
    "urlpart = re.search(r'(\\w+?)\\.\\w{2,4}(?=\\/)', url).group(1)\n",
    "namepart = re.search(r'\\.\\w{2,4}(\\/.+\\.pdf)', url).group(1).replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n",
    "filename = urlpart + namepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldbank-governance-wgi-Home-downLoadFile?fileName=va.pdf'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
