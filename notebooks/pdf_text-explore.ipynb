{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "import re\n",
    "import pdfplumber\n",
    "import spacy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(20,12)})\n",
    "\n",
    "data_path = os.path.join(\"D:/\", \"data\", \"drmkc\", \"pdfs\", \"drmkc.jrc.ec.europa.eu\")\n",
    "work_path = os.path.join(\"D:/\", \"data\", \"drmkc\", \"work\")\n",
    "filenames = [join(data_path,f) for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "filenames = [filename for filename in filenames if filename.endswith('.pdf')]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "nlp.max_length = 2500000\n",
    "\n",
    "mallet_path = os.path.join('C:\\\\', 'mallet', 'mallet-2.0.8', 'bin', 'mallet.bat') # update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|==================================================| 100.00 %\r"
     ]
    }
   ],
   "source": [
    "problem_files = []\n",
    "\n",
    "for c, filename in enumerate(filenames, start = 1):\n",
    "    \n",
    "    if filename in [entry.get('filename') for entry in data]:\n",
    "        continue\n",
    "    \n",
    "    progress = \"|{0}| {1:.2f} %\".format((\"=\"*int(c/len(filenames) * 50)).ljust(50), c/len(filenames) * 100)\n",
    "    \n",
    "    entry = {}\n",
    "    entry['filename'] = filename\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(join(data_path, filename)) as pdf:\n",
    "            try:\n",
    "                pdf_text = '\\n'.join([page.extract_text() for page in pdf.pages if page.extract_text() is not None])\n",
    "                entry['text'] = pdf_text\n",
    "            except Exception as e:\n",
    "                print(filename)\n",
    "                raise e\n",
    "    except:\n",
    "        problem_files.append(filename)\n",
    "    \n",
    "    data.append(entry)\n",
    "    \n",
    "    print(progress, end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [entry for entry in data if 'text' in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "stop_words = list(nlp.Defaults.stop_words)\n",
    "                                            \n",
    "def tokenizer_custom(text, stop_words=stop_words, tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "       \n",
    "    text = text.replace('\\n', ' ')\n",
    "    numbers_re = r\".*\\d.*\"\n",
    "    punct_regex = r\"[^\\w\\s]\"\n",
    "    \n",
    "    doc = nlp(text)\n",
    "        \n",
    "    pos_tags = tags # Keeps proper nouns, adjectives and nouns\n",
    "    \n",
    "    exceptions = []\n",
    "    \n",
    "    tokens = []\n",
    "      \n",
    "    for word in doc:\n",
    "        if ((word.pos_ in pos_tags) or (any([exception in word.text for exception in exceptions]))) and (len(word.lemma_) > 4) and (word.lemma_.lower() not in stop_words) and not (re.match(numbers_re, word.lemma_.lower())):\n",
    "            token = word.lemma_.lower() # Returning the word in lower-case.\n",
    "            token = re.sub(punct_regex, \"\", token)\n",
    "            tokens.append(token)\n",
    "\n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "def create_tfidfdtm(df, tokensvar = 'tokens'):\n",
    "\n",
    "    def return_tokens(tokens):\n",
    "        return tokens\n",
    "\n",
    "    text_tokens = df['tokens']\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=return_tokens,\n",
    "        preprocessor=return_tokens,\n",
    "        token_pattern=None,\n",
    "        min_df = 5,\n",
    "        max_df = 0.9\n",
    "        )\n",
    "\n",
    "    transformed_documents = vectorizer.fit_transform(text_tokens)\n",
    "\n",
    "    transformed_documents_as_array = transformed_documents.toarray()\n",
    "    tfidf_dtm = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names())\n",
    "    \n",
    "    return(tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|==================================================| 100.00 %\r"
     ]
    }
   ],
   "source": [
    "pos_tags = ['NOUN', 'ADJ', 'PROPN']\n",
    "\n",
    "for c, entry in enumerate(data, start = 1):\n",
    "    entry['tokens'] = tokenizer_custom(entry.get('text'), tags = pos_tags)\n",
    "    \n",
    "    progress = \"|{0}| {1:.2f} %\".format((\"=\"*int(c/len(data) * 50)).ljust(50), c/len(data) * 100)\n",
    "    print(progress, end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = \"drmkc-pdfs_tokenized.json\"\n",
    "\n",
    "with open(os.path.join(work_path, outname), 'w', encoding = 'utf-8') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data)\n",
    "df['text_id'] = pd.Series(df.index).apply(lambda i: \"text_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.explode('tokens').rename(columns = {'tokens': 'token'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disaster      7570\n",
       "hazard        5460\n",
       "assessment    4706\n",
       "european      4310\n",
       "management    4133\n",
       "climate       3868\n",
       "flood         3795\n",
       "change        3620\n",
       "system        3480\n",
       "impact        3278\n",
       "natural       3205\n",
       "level         2977\n",
       "research      2908\n",
       "journal       2906\n",
       "event         2805\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long['token'].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = create_tfidfdtm(df)\n",
    "\n",
    "tfidf_tidy = tfidf.melt(var_name='token', value_name = 'tf-idf', ignore_index = False)\n",
    "tfidf_tidy['text_id'] = pd.Series(tfidf_tidy.index).apply(lambda i: \"text_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_unique = df_long.drop_duplicates(subset = ['filename', 'token'])\n",
    "\n",
    "df_tfidf = pd.merge(df_long_unique, tfidf_tidy, how = \"left\", on = [\"text_id\", \"token\"])\n",
    "\n",
    "df_tfidf = pd.merge(df_tfidf, df.loc[:, 'tokens'], how = \"left\", left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>text_id</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\nFlood damage survey after ma...</td>\n",
       "      <td>flood</td>\n",
       "      <td>text_0</td>\n",
       "      <td>0.475326</td>\n",
       "      <td>[flood, damage, survey, major, flood, norway, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\nFlood damage survey after ma...</td>\n",
       "      <td>damage</td>\n",
       "      <td>text_0</td>\n",
       "      <td>0.379561</td>\n",
       "      <td>[fifth, technical, workshop, approach, damage,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\nFlood damage survey after ma...</td>\n",
       "      <td>survey</td>\n",
       "      <td>text_0</td>\n",
       "      <td>0.136319</td>\n",
       "      <td>[european, commission, brussels, final, commis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\nFlood damage survey after ma...</td>\n",
       "      <td>major</td>\n",
       "      <td>text_0</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>[european, commission, brussels, final, commis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\nFlood damage survey after ma...</td>\n",
       "      <td>norway</td>\n",
       "      <td>text_0</td>\n",
       "      <td>0.272853</td>\n",
       "      <td>[inform, index, methodology, result, poljanšek...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...   \n",
       "1  D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...   \n",
       "2  D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...   \n",
       "3  D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...   \n",
       "4  D:/data\\drmkc\\pdfs\\drmkc.jrc.ec.europa.eu\\ec--...   \n",
       "\n",
       "                                                text   token text_id  \\\n",
       "0   \\n \\n \\n \\n \\n \\nFlood damage survey after ma...   flood  text_0   \n",
       "1   \\n \\n \\n \\n \\n \\nFlood damage survey after ma...  damage  text_0   \n",
       "2   \\n \\n \\n \\n \\n \\nFlood damage survey after ma...  survey  text_0   \n",
       "3   \\n \\n \\n \\n \\n \\nFlood damage survey after ma...   major  text_0   \n",
       "4   \\n \\n \\n \\n \\n \\nFlood damage survey after ma...  norway  text_0   \n",
       "\n",
       "     tf-idf                                             tokens  \n",
       "0  0.475326  [flood, damage, survey, major, flood, norway, ...  \n",
       "1  0.379561  [fifth, technical, workshop, approach, damage,...  \n",
       "2  0.136319  [european, commission, brussels, final, commis...  \n",
       "3  0.047615  [european, commission, brussels, final, commis...  \n",
       "4  0.272853  [inform, index, methodology, result, poljanšek...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token\n",
       "gdacs            0.233951\n",
       "cascais          0.183807\n",
       "inform           0.154161\n",
       "interviewer      0.148301\n",
       "florence         0.146865\n",
       "interview        0.139257\n",
       "disaster         0.138575\n",
       "journal          0.129900\n",
       "stakeholders     0.124228\n",
       "lunch            0.115440\n",
       "garden           0.115329\n",
       "natech           0.115279\n",
       "hazard           0.113603\n",
       "climate          0.112572\n",
       "activities       0.109901\n",
       "drought          0.107719\n",
       "covenant         0.104495\n",
       "flood            0.103372\n",
       "                 0.100763\n",
       "click            0.100499\n",
       "hp               0.095204\n",
       "personal         0.093373\n",
       "alarm            0.089924\n",
       "assessment       0.089092\n",
       "european         0.086322\n",
       "april            0.084621\n",
       "graphic          0.081067\n",
       "peril            0.079656\n",
       "regret           0.079199\n",
       "surminski        0.078691\n",
       "sparks           0.078254\n",
       "change           0.077848\n",
       "desinventar      0.076916\n",
       "authors          0.075976\n",
       "management       0.075072\n",
       "safety           0.074929\n",
       "datum            0.074211\n",
       "accident         0.073240\n",
       "natural          0.072419\n",
       "contributing     0.071864\n",
       "earthquake       0.070299\n",
       "conversation     0.069962\n",
       "volcanic         0.069848\n",
       "identifier       0.068468\n",
       "geophysical      0.068213\n",
       "answer           0.066925\n",
       "communication    0.066414\n",
       "aristizabal      0.065542\n",
       "woodworth        0.065497\n",
       "chemical         0.065457\n",
       "Name: tf-idf, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.groupby('token')['tf-idf'].mean().sort_values(ascending = False)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for entry in data:\n",
    "    sentences = entry.get('text').split(\"\\n\")\n",
    "    all_sentences = all_sentences + sentences\n",
    "\n",
    "sentence_tokens = []\n",
    "\n",
    "for sentence in all_sentences:\n",
    "    tokens = tokenizer_custom(sentence)\n",
    "    sentence_tokens.append(tokens)\n",
    "    \n",
    "print(len(sentence_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sentence_tokens, window=5, min_count=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trigger', 0.7434147596359253),\n",
       " ('seismic', 0.6870116591453552),\n",
       " ('industrial', 0.6807842254638672),\n",
       " ('landslide', 0.6502715349197388),\n",
       " ('geophysical', 0.642982006072998),\n",
       " ('collapse', 0.6396244764328003),\n",
       " ('flash', 0.6273693442344666),\n",
       " ('multiple', 0.6260375380516052),\n",
       " ('installation', 0.6246126294136047),\n",
       " ('frequent', 0.6229647994041443)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('earthquake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://web.stanford.edu/class/cs224n/materials/Gensim%20word%20vector%20visualization.html\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model.wv.__getitem__(w) for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_pca_scatterplot(model = model, words = ['climate', 'disaster', 'flooding', 'earthquake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47197855, -0.22610386,  0.12468266, -0.11042812,  0.08864352,\n",
       "       -0.682457  , -0.62890935, -0.03651674,  0.12019701,  0.5866998 ,\n",
       "        0.29930466, -0.11338794,  0.640254  , -0.34219185,  0.78748894,\n",
       "        1.0230747 ,  0.21799916,  0.14618126,  0.7312597 , -0.9240628 ,\n",
       "       -1.3315586 ,  0.68454623, -0.7056176 ,  0.34107652,  0.330009  ,\n",
       "       -0.42169073, -0.4077712 ,  0.427205  , -0.26099563,  0.21202241,\n",
       "       -0.19059819,  0.08945513,  0.43145093,  0.19888516, -0.2777784 ,\n",
       "       -0.46523273, -0.02421776, -0.28987938, -1.0342307 , -0.86499166,\n",
       "       -0.5399945 ,  0.798581  , -0.77354527,  0.4197254 ,  0.33842027,\n",
       "       -0.37107962,  0.54595447,  0.9473916 ,  0.74748546, -0.81370944,\n",
       "        0.98479897, -0.06068896, -0.12833127,  0.34784728, -0.29855523,\n",
       "        0.668138  , -0.30409333,  0.26043788, -0.594141  ,  0.3514604 ,\n",
       "       -0.69111484,  0.63024527,  1.0151523 ,  0.2902618 ,  1.1976529 ,\n",
       "        1.1316167 , -0.14451939, -0.6066962 , -1.3420815 , -0.4049654 ,\n",
       "       -0.31655607, -0.84413743, -0.9752981 , -1.0480326 ,  0.6444368 ,\n",
       "        0.16842113, -0.23841187,  0.09410815,  0.11520447, -0.19421504,\n",
       "       -0.41023937,  1.0256518 ,  0.2845105 ,  1.3140273 , -0.28519878,\n",
       "       -0.9048875 , -0.29447728,  0.2532969 ,  0.7204421 , -1.0118432 ,\n",
       "       -0.8397134 ,  0.18262407, -0.18807305,  0.78188616,  0.2885481 ,\n",
       "       -0.65735686,  0.01906109,  0.32020447,  0.7320408 , -0.9669567 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.__getitem__('climate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = [entry.get('tokens') for entry in data]\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(tokens_list) # integer id per word\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(tokens) for tokens in tokens_list] # bag-of-word(bow) tuple for each text - id, count\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=id2word)\n",
    "lda_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(lda_model.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score - https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=comments_tokens, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamodel = coherence_model_lda.get_coherence() \n",
    "print('\\nCoherence Score: ', coherence_ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting dominant topic for one corpus entry (bag-of-word tuple - bowt)\n",
    "def get_dominant_topic(corpus_bowt, ldamodel = lda_model):\n",
    "    \n",
    "    dominant_topic_dict = dict()\n",
    "    \n",
    "    topics_doc = ldamodel[corpus_bowt]\n",
    "    \n",
    "    dominant_topic = sorted(topics_doc, key = lambda t: t[1], reverse = True)[0]\n",
    "    topic_num = dominant_topic[0]\n",
    "    topic_prob = dominant_topic[1]\n",
    "    \n",
    "    topic_kws = [word for word, prop in ldamodel.show_topic(topic_num)]\n",
    "    \n",
    "    dominant_topic_dict['dominant_topic'] = topic_num\n",
    "    dominant_topic_dict['topic_probability'] = topic_prob\n",
    "    dominant_topic_dict['topic_keywords'] = topic_kws\n",
    "    \n",
    "    return(dominant_topic_dict) # Note that domninant topic info is returned as dictionary\n",
    "\n",
    "# Creating list of dictionaries - one dictionary contatining dominant topic info for each corpus entry\n",
    "corpus_dominant_topics = list()\n",
    "for bowt in corpus:\n",
    "    dominant_topic = get_dominant_topic(bowt)\n",
    "    corpus_dominant_topics.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "\n",
    "- [x] Read in pdfs\n",
    "- [x] tokenize\n",
    "- [ ] filter keywords\n",
    "- [ ] keyword analysis\n",
    "- [ ] topic model (see reddit-miner example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
